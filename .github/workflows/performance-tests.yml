name: Performance Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run every day at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:  # Allow manual trigger

jobs:
  performance-test:
    runs-on: ubuntu-latest
    
    services:
      # Start backend service
      backend:
        image: python:3.11
        ports:
          - 8000:8000
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install requests
      
      - name: Start backend server
        run: |
          cd ${{ github.workspace }}
          python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 &
          sleep 10  # Wait for server to start
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GOOGLE_CLOUD_PROJECT: ${{ secrets.GOOGLE_CLOUD_PROJECT }}
          FIREBASE_API_KEY: ${{ secrets.FIREBASE_API_KEY }}
      
      - name: Wait for backend to be ready
        run: |
          timeout 30 bash -c 'until curl -f http://localhost:8000/health; do sleep 1; done'
      
      - name: Run performance tests
        run: |
          python test_performance.py
        continue-on-error: true
      
      - name: Upload performance results
        uses: actions/upload-artifact@v3
        with:
          name: performance-results
          path: performance_results.json
      
      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('performance_results.json', 'utf8'));
            
            let comment = '## üöÄ Performance Test Results\n\n';
            comment += `**Success Rate**: ${results.summary.success_rate}%\n`;
            comment += `**Passed**: ${results.summary.passed}/${results.summary.total}\n\n`;
            comment += '| Test | Avg (ms) | P95 (ms) | Limit (ms) | Status |\n';
            comment += '|------|----------|----------|------------|--------|\n';
            
            results.results.forEach(r => {
              const status = r.passed ? '‚úÖ' : '‚ùå';
              comment += `| ${r.name} | ${r.avg_ms || 'N/A'} | ${r.p95_ms || 'N/A'} | ${r.threshold_ms} | ${status} |\n`;
            });
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
      
      - name: Fail if performance tests failed
        run: |
          if [ -f performance_results.json ]; then
            SUCCESS_RATE=$(jq '.summary.success_rate' performance_results.json)
            if (( $(echo "$SUCCESS_RATE < 80" | bc -l) )); then
              echo "‚ùå Performance tests failed (success rate: $SUCCESS_RATE%)"
              exit 1
            fi
          fi

